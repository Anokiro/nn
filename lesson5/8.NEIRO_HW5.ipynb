{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vQnDWSn8TEOl"
   },
   "source": [
    "# Введение в искусственные нейронные сети\n",
    "# Урок 5. Рекуррентные нейронные сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Попробуйте изменить параметры нейронной сети, работающей с датасетом imdb, либо нейронной сети, работающей airline-passengers (она прилагается вместе с датасетом к уроку в виде отдельного скрипта) так, чтобы улучшить её точность. Приложите анализ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "wuI6h_TyEhvl"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow.keras.utils as ku \n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import  SimpleRNN, LSTM, GRU, Flatten,  Conv1D, Conv2D,  Dropout, Bidirectional\n",
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imdb загружает набор данных IMDB.\n",
    "\n",
    "Набор данных состоит из 25 000 рецензий к фильмам от IMDB и имеет положительные или отрицательные метки. Рецензии были предварительно обработаны, и каждая рецензия кодируется как список индексов слов (целых чисел). Для удобства слова индексируются по общей частоте в наборе данных, так что, например, целое число \"3\" кодирует 3-е наиболее частое слово в данных. Это позволяет выполнять быстрые операции фильтрации.\n",
    "\n",
    "Как правило, \"0\" означает не конкретное слово, а используется для кодирования любого неизвестного слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка данных...\n",
      "25000 тренировочные последовательности\n",
      "25000 тестовые последовательности\n"
     ]
    }
   ],
   "source": [
    "max_features = 10000\n",
    "\n",
    "# Каждый отзыв(рецензия) имеею разную длину уникальных слов, поэтому необходимо обрезать отзыв и сделать векторы равной длины.\n",
    "# Нейронка принимает только равные по длине векторы!\n",
    "# обрезание текстов после данного количества слов (среди top max_features наиболее используемые слова)\n",
    "maxlen = 80\n",
    "batch_size = 50 # увеличьте значение для ускорения обучения\n",
    "\n",
    "print('Загрузка данных...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(x_train), 'тренировочные последовательности')\n",
    "print(len(x_test), 'тестовые последовательности')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88584"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = imdb.get_word_index()\n",
    "len(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'N_reviews < maxlen')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Проверим сколько отзывов имеют длину меньше заданной длины maxlen\n",
    "list_loss_len = []\n",
    "for num_ in range(200):\n",
    "    less_then_maxlen = [ii for ii in range(len(x_train)) if (len(x_train[ii]) < num_ )]\n",
    "    list_loss_len.append(len(less_then_maxlen))\n",
    "\n",
    "plt.plot(range(len(list_loss_len)), list_loss_len)\n",
    "plt.xlabel('maxlen')\n",
    "plt.ylabel('N_reviews < maxlen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad последовательности (примеров в x единицу времени)\n",
      "x_train shape: (25000, 80)\n",
      "x_test shape: (25000, 80)\n"
     ]
    }
   ],
   "source": [
    "print('Pad последовательности (примеров в x единицу времени)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train[6719])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    1,   13,  586,  851,   14,   31,   60,   23,\n",
       "       2863, 2364,  314])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[6719]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_seq(data, xLen = 100, step = 1):\n",
    "    results = np.zeros((len(data), xLen, 1))\n",
    "    for i, sequence in enumerate(data):\n",
    "        for j in range(xLen):\n",
    "            results[i, j, :] = sequence[j]           \n",
    "    return results\n",
    " \n",
    "data_train_seq = vectorize_seq(x_train, xLen = 80)\n",
    "data_test_seq = vectorize_seq(x_test, xLen = 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.500e+01, 2.560e+02, 4.000e+00, 2.000e+00, 7.000e+00, 3.766e+03,\n",
       "       5.000e+00, 7.230e+02, 3.600e+01, 7.100e+01, 4.300e+01, 5.300e+02,\n",
       "       4.760e+02, 2.600e+01, 4.000e+02, 3.170e+02, 4.600e+01, 7.000e+00,\n",
       "       4.000e+00, 2.000e+00, 1.029e+03, 1.300e+01, 1.040e+02, 8.800e+01,\n",
       "       4.000e+00, 3.810e+02, 1.500e+01, 2.970e+02, 9.800e+01, 3.200e+01,\n",
       "       2.071e+03, 5.600e+01, 2.600e+01, 1.410e+02, 6.000e+00, 1.940e+02,\n",
       "       7.486e+03, 1.800e+01, 4.000e+00, 2.260e+02, 2.200e+01, 2.100e+01,\n",
       "       1.340e+02, 4.760e+02, 2.600e+01, 4.800e+02, 5.000e+00, 1.440e+02,\n",
       "       3.000e+01, 5.535e+03, 1.800e+01, 5.100e+01, 3.600e+01, 2.800e+01,\n",
       "       2.240e+02, 9.200e+01, 2.500e+01, 1.040e+02, 4.000e+00, 2.260e+02,\n",
       "       6.500e+01, 1.600e+01, 3.800e+01, 1.334e+03, 8.800e+01, 1.200e+01,\n",
       "       1.600e+01, 2.830e+02, 5.000e+00, 1.600e+01, 4.472e+03, 1.130e+02,\n",
       "       1.030e+02, 3.200e+01, 1.500e+01, 1.600e+01, 5.345e+03, 1.900e+01,\n",
       "       1.780e+02, 3.200e+01])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_seq[0,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Построение модели...\n",
      "Процесс обучения...\n",
      "250/250 [==============================] - 28s 104ms/step - loss: 0.6909 - accuracy: 0.5310 - val_loss: 0.6877 - val_accuracy: 0.5409\n",
      "782/782 [==============================] - 14s 18ms/step - loss: 0.6877 - accuracy: 0.5409\n",
      "Результат при тестировании: 0.6877272129058838\n",
      "Тестовая точность: 0.5409200191497803\n"
     ]
    }
   ],
   "source": [
    "#простая модель\n",
    "\n",
    "print('Построение модели...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(128,return_sequences = False,input_shape = ( 80,1)))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "# стоит попробовать использовать другие оптимайзер и другие конфигурации оптимайзеров \n",
    "model.compile(loss = 'binary_crossentropy',\n",
    "              optimizer = 'adam',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "print('Процесс обучения...')\n",
    "model.fit(data_train_seq, y_train,\n",
    "          batch_size = 100,\n",
    "          epochs = 1, # увеличьте при необходимости\n",
    "          validation_data = (data_test_seq, y_test))\n",
    "\n",
    "score, acc = model.evaluate(data_test_seq, y_test,\n",
    "#                             batch_size = batch_size\n",
    "                           )\n",
    "print('Результат при тестировании:', score)\n",
    "print('Тестовая точность:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Построение модели...\n",
      "Процесс обучения...\n",
      "834/834 [==============================] - 38s 43ms/step - loss: 0.4596 - accuracy: 0.7726 - val_loss: 0.3595 - val_accuracy: 0.8404\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.3595 - accuracy: 0.8404\n",
      "Результат при тестировании: 0.35953739285469055\n",
      "Тестовая точность: 0.8404399752616882\n"
     ]
    }
   ],
   "source": [
    "#сложнее модель\n",
    "\n",
    "print('Построение модели...')\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding( max_features,16))\n",
    "# model.add(LSTM(8, dropout = 0.2, recurrent_dropout = 0.2, return_sequences = True))\n",
    "\n",
    "# при переходе к полносвязному слою \"return_sequences = True\" необходимо отключать!\n",
    "model.add(LSTM(16, dropout = 0.1, recurrent_dropout = 0.3))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy',\n",
    "              optimizer = 'adam',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "print('Процесс обучения...')\n",
    "model.fit(data_train_seq, y_train,\n",
    "          batch_size = 30,\n",
    "          epochs = 1, # увеличьте при необходимости\n",
    "          validation_data = (data_test_seq, y_test))\n",
    "\n",
    "score, acc = model.evaluate(data_test_seq, y_test,\n",
    "#                             batch_size = batch_size\n",
    "                           )\n",
    "print('Результат при тестировании:', score)\n",
    "print('Тестовая точность:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Понижение размера батча(пакет размером 20 - 50) немного увеличивает метрику. Подбор более оптимального dropout также немного увеличивает метрику.\n",
    "\n",
    "Подбор оптимайзера в данном случае практически не влияет на метрику в лучшую сторону(лучший результат с оптимайзером Adam), увеличение количества нейронов > 128 также практически не прибавляет качества(и увеличивает время работы). Использование слоя GRU(или слоёв только на GRU) не приводит к улучшению метрики. Увеличение колчества LSTM слоев не приводит к улучшению качества, как и количества полносвязных слоев.\n",
    "\n",
    "Использование SimpleRNN значительно ухудшает метрику. Использование activation = 'linear' в выходном слое ухудшает метрику.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) Попробуйте изменить параметры нейронной сети, генерирующей текст таким образом, чтобы добиться генерации как можно более осмысленного текста. Пришлите лучший текст из получившихся и опишите предпринятые для его получения действия. Можно использовать текст другого произведения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=10000)\n",
    "\n",
    "data = open('alice_in_wonderland.txt', encoding=\"utf-8\").read()\n",
    "#Читаем текст\n",
    "corpus = data.lower().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['project gutenberg’s alice’s adventures in wonderland, by lewis carroll',\n",
       " '',\n",
       " 'this ebook is for the use of anyone anywhere at no cost and with',\n",
       " 'almost no restrictions whatsoever.  you may copy it, give it away or',\n",
       " 're-use it under the terms of the project gutenberg license included',\n",
       " 'with this ebook or online at www.gutenberg.org',\n",
       " '',\n",
       " '',\n",
       " 'title: alice’s adventures in wonderland',\n",
       " '',\n",
       " 'author: lewis carroll',\n",
       " '',\n",
       " 'posting date: june 25, 2008 [ebook #11]',\n",
       " 'release date: march, 1994',\n",
       " 'last updated: october 6, 2016',\n",
       " '',\n",
       " 'language: english',\n",
       " '',\n",
       " 'character set encoding: utf-8',\n",
       " '',\n",
       " '*** start of this project gutenberg ebook alice’s adventures in wonderland ***',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'alice’s adventures in wonderland',\n",
       " '',\n",
       " 'lewis carroll',\n",
       " '',\n",
       " 'the millennium fulcrum edition 3.0',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'chapter i. down the rabbit-hole',\n",
       " '',\n",
       " 'alice was beginning to get very tired of sitting by her sister on the',\n",
       " 'bank, and of having nothing to do: once or twice she had peeped into the',\n",
       " 'book her sister was reading, but it had no pictures or conversations in',\n",
       " 'it, ‘and what is the use of a book,’ thought alice ‘without pictures or',\n",
       " 'conversations?’',\n",
       " '',\n",
       " 'so she was considering in her own mind (as well as she could, for the',\n",
       " 'hot day made her feel very sleepy and stupid), whether the pleasure']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts( corpus)\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "# create input sequences using list of tokens\n",
    "input_sequences = []\n",
    "for line in corpus:\n",
    "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
    "\tfor i in range(1, len(token_list)):\n",
    "\t\tn_gram_sequence = token_list[:i+1]\n",
    "\t\tinput_sequences.append(n_gram_sequence)\n",
    "\n",
    "\n",
    "# pad sequences \n",
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "\n",
    "# create predictors and label\n",
    "predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "\n",
    "label = ku.to_categorical(label, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1840"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['posting']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28231, 3399)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = EarlyStopping( monitor = 'val_accuracy', patience = 10) # создаем обратный вызов - calback - тут \"Ранняя остановка\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_26 (Embedding)    (None, 17, 256)           870144    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 17, 100)          122800    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " lstm_37 (LSTM)              (None, 32)                17024     \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 1699)              56067     \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 3399)              5778300   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,844,335\n",
      "Trainable params: 6,844,335\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 256, input_length = max_sequence_len-1)) \n",
    "# вложение тренируемое для перехода от слова к его векторному коду \n",
    "# на вход вложения (эмбединга) передаем вектор словарь (длина равна словарю, вектор разреженный)), \n",
    "#   на выход строим вектор из n (тут 256) координат - он плотный\n",
    "model.add(Bidirectional(LSTM(50, return_sequences = True)))\n",
    "\n",
    "model.add(LSTM(32, dropout = 0.1, recurrent_dropout = 0.3))\n",
    "# model.add(Dropout( 0.2))\n",
    "model.add(Dense(total_words/2, activation = 'relu', kernel_regularizer = regularizers.l2(0.01)))\n",
    "model.add(Dense(total_words, activation = 'softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "706/706 [==============================] - 64s 83ms/step - loss: 6.1936 - accuracy: 0.0562 - val_loss: 7.0019 - val_accuracy: 0.0519\n",
      "Epoch 2/25\n",
      "706/706 [==============================] - 57s 81ms/step - loss: 5.7172 - accuracy: 0.0718 - val_loss: 7.1703 - val_accuracy: 0.0781\n",
      "Epoch 3/25\n",
      "706/706 [==============================] - 56s 79ms/step - loss: 5.4770 - accuracy: 0.0936 - val_loss: 7.3011 - val_accuracy: 0.0820\n",
      "Epoch 4/25\n",
      "706/706 [==============================] - 56s 79ms/step - loss: 5.2824 - accuracy: 0.1063 - val_loss: 7.5345 - val_accuracy: 0.0912\n",
      "Epoch 5/25\n",
      "706/706 [==============================] - 56s 80ms/step - loss: 5.1230 - accuracy: 0.1176 - val_loss: 7.5225 - val_accuracy: 0.0978\n",
      "Epoch 6/25\n",
      "706/706 [==============================] - 56s 79ms/step - loss: 4.9759 - accuracy: 0.1336 - val_loss: 7.8231 - val_accuracy: 0.0942\n",
      "Epoch 7/25\n",
      "706/706 [==============================] - 56s 79ms/step - loss: 4.8422 - accuracy: 0.1463 - val_loss: 7.9381 - val_accuracy: 0.1020\n",
      "Epoch 8/25\n",
      "706/706 [==============================] - 56s 79ms/step - loss: 4.7160 - accuracy: 0.1569 - val_loss: 7.9883 - val_accuracy: 0.0958\n",
      "Epoch 9/25\n",
      "706/706 [==============================] - 56s 79ms/step - loss: 4.6032 - accuracy: 0.1700 - val_loss: 8.1104 - val_accuracy: 0.1087\n",
      "Epoch 10/25\n",
      "706/706 [==============================] - 55s 79ms/step - loss: 4.4972 - accuracy: 0.1790 - val_loss: 8.3418 - val_accuracy: 0.1094\n",
      "Epoch 11/25\n",
      "706/706 [==============================] - 56s 80ms/step - loss: 4.4000 - accuracy: 0.1869 - val_loss: 8.2592 - val_accuracy: 0.1068\n",
      "Epoch 12/25\n",
      "706/706 [==============================] - 56s 79ms/step - loss: 4.3073 - accuracy: 0.1959 - val_loss: 8.5584 - val_accuracy: 0.1082\n",
      "Epoch 13/25\n",
      "706/706 [==============================] - 56s 80ms/step - loss: 4.2216 - accuracy: 0.2020 - val_loss: 8.7370 - val_accuracy: 0.1055\n",
      "Epoch 14/25\n",
      "706/706 [==============================] - 56s 79ms/step - loss: 4.1328 - accuracy: 0.2113 - val_loss: 8.9411 - val_accuracy: 0.1070\n",
      "Epoch 15/25\n",
      "706/706 [==============================] - 56s 80ms/step - loss: 4.0540 - accuracy: 0.2167 - val_loss: 9.2056 - val_accuracy: 0.1084\n",
      "Epoch 16/25\n",
      "706/706 [==============================] - 56s 79ms/step - loss: 3.9756 - accuracy: 0.2256 - val_loss: 9.3957 - val_accuracy: 0.1075\n",
      "Epoch 17/25\n",
      "706/706 [==============================] - 56s 79ms/step - loss: 3.8981 - accuracy: 0.2322 - val_loss: 9.4794 - val_accuracy: 0.1070\n",
      "Epoch 18/25\n",
      "706/706 [==============================] - 56s 79ms/step - loss: 3.8277 - accuracy: 0.2408 - val_loss: 9.8493 - val_accuracy: 0.0990\n",
      "Epoch 19/25\n",
      "706/706 [==============================] - 56s 80ms/step - loss: 3.7575 - accuracy: 0.2470 - val_loss: 10.0289 - val_accuracy: 0.1025\n",
      "Epoch 20/25\n",
      "706/706 [==============================] - 56s 79ms/step - loss: 3.6893 - accuracy: 0.2563 - val_loss: 10.1851 - val_accuracy: 0.1041\n"
     ]
    }
   ],
   "source": [
    "# перезапустить, не дожидаясь конца\n",
    "history = model.fit(predictors, label, epochs=25, validation_split=0.2, callbacks=[callback],verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 13, 1018, 10, 17, 409, 377]\n",
      "[12, 13, 1018, 10, 17, 409, 377, 19]\n",
      "[12, 13, 1018, 10, 17, 409, 377, 19, 72]\n",
      "[12, 13, 1018, 10, 17, 409, 377, 19, 72, 163]\n",
      "[12, 13, 1018, 10, 17, 409, 377, 19, 72, 163, 16]\n",
      "[12, 13, 1018, 10, 17, 409, 377, 19, 72, 163, 16, 7]\n",
      "[12, 13, 1018, 10, 17, 409, 377, 19, 72, 163, 16, 7, 13]\n",
      "[12, 13, 1018, 10, 17, 409, 377, 19, 72, 163, 16, 7, 13, 29]\n",
      "Alice was considering in her own mind at its eyes as she was very earnestly\n"
     ]
    }
   ],
   "source": [
    "# начальная строка\n",
    "# seed_text = \"alice opened the door and\"\n",
    "seed_text = \"Alice was considering in her own mind\"\n",
    "\n",
    "next_words = 8\n",
    "  \n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    print(token_list)\n",
    "    token_list = pad_sequences([token_list], maxlen = max_sequence_len-1, padding='pre')\n",
    "  #predicted = model.predict_classes(token_list, verbose=0)\n",
    "    output_word = \"\"\n",
    "    y_p = model.predict(token_list)\n",
    "    y_predict = y_p * np.random.random(  size = (1,y_p.shape[1]))\n",
    "    predicted_ind = np.argmax(y_predict,axis = 1)\n",
    "    \n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted_ind:\n",
    "            output_word = word\n",
    "            break\n",
    "    seed_text += \" \" + output_word\n",
    "print(seed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алиса мысленно рассматривала его глаза, так как она была очень серьезна"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чем длинее выстраивается фраза, тем менее она адекватна(т.е. алгоритм выдает что-то несуразное). Более-менее \"осмысленно\" выстраиваются средние фразы (до 20 слов), хотя получить от данного алгоритма что-то хорошо выстроенное очень непросто - пока в данном случае единственным вариантом является выстраивание фразы по частям(когда алгоритм выдал что-то вменяемое, а затем к этому добавлять следующее, при этом прийдется вручную определять адекватность куска фразы)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "metodich5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
